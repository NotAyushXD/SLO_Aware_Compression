{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from preprocessing import DataPreprocessor\n",
    "from server import SingleVariantServer\n",
    "from load_generator import ClosedLoopLoadGenerator\n",
    "from metrics import MetricsCalculator\n",
    "from evaluation import HeldOutEvaluator\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Configuration\n",
    "# -------------------------\n",
    "\n",
    "PREPROCESS = False\n",
    "\n",
    "DATA_DIR = \"data/raw\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "\n",
    "MODEL_NAME_OR_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# OR local path (we'll discuss this below)\n",
    "# MODEL_NAME_OR_PATH = \"/mnt/models/llama-2-7b-chat\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DTYPE = \"auto\"\n",
    "\n",
    "NUM_REQUESTS = 5000\n",
    "CONCURRENCIES = [1, 2, 4, 8, 16, 32]\n",
    "\n",
    "DATA_SUBSET = 0  # 0 = full data\n",
    "\n",
    "OUTPUT_DIR = \"results/baseline_med\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS:\n",
    "    logger.info(\"[STEP 0] Preprocessing data\")\n",
    "\n",
    "    preprocessor = DataPreprocessor(\n",
    "        data_dir=DATA_DIR,\n",
    "        output_dir=PROCESSED_DIR\n",
    "    )\n",
    "    train_data, val_data, test_data = preprocessor.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    splits = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "    for split in splits:\n",
    "        path = os.path.join(data_dir, f\"{split}_data.jsonl\")\n",
    "        if not os.path.exists(path):\n",
    "            logger.warning(f\"Missing {path}\")\n",
    "            continue\n",
    "\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    splits[split].append(json.loads(line))\n",
    "\n",
    "    return splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = load_data(PROCESSED_DIR)\n",
    "\n",
    "assert len(val_data) > 0 and len(test_data) > 0, \"Validation/Test data missing\"\n",
    "\n",
    "if DATA_SUBSET > 0:\n",
    "    val_data = val_data[:DATA_SUBSET]\n",
    "    test_data = test_data[:DATA_SUBSET]\n",
    "\n",
    "logger.info(f\"Loaded val={len(val_data)}, test={len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"[STEP 2] Initializing server\")\n",
    "\n",
    "server = SingleVariantServer(\n",
    "    model_name=MODEL_NAME_OR_PATH,\n",
    "    variant=\"med\",\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_gen = ClosedLoopLoadGenerator(\n",
    "    inference_func=server.generate,\n",
    "    max_concurrency=1,\n",
    "    num_requests=10,\n",
    "    data_loader=val_data\n",
    ")\n",
    "\n",
    "metrics = load_gen.run()\n",
    "calc = MetricsCalculator(metrics)\n",
    "calc.print_report(\"SANITY CHECK (Concurrency=1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_summary = {}\n",
    "\n",
    "for concurrency in CONCURRENCIES:\n",
    "    logger.info(f\"Running load test: concurrency={concurrency}\")\n",
    "\n",
    "    load_gen = ClosedLoopLoadGenerator(\n",
    "        inference_func=server.generate,\n",
    "        max_concurrency=concurrency,\n",
    "        num_requests=NUM_REQUESTS,\n",
    "        data_loader=val_data\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    raw_metrics = load_gen.run()\n",
    "    duration = time.time() - start\n",
    "\n",
    "    calc = MetricsCalculator(raw_metrics)\n",
    "    metrics = calc.compute_all_metrics()\n",
    "\n",
    "    calc.print_report(f\"Concurrency {concurrency}\")\n",
    "\n",
    "    # Save\n",
    "    calc.save_metrics(f\"{OUTPUT_DIR}/metrics_{concurrency}.json\")\n",
    "    load_gen.save_metrics(f\"{OUTPUT_DIR}/requests_{concurrency}.jsonl\")\n",
    "\n",
    "    all_metrics_summary[concurrency] = {\n",
    "        \"metrics\": metrics,\n",
    "        \"duration_sec\": duration\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = HeldOutEvaluator(\n",
    "    model=server,\n",
    "    data_loader=test_data,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "eval_results = evaluator.evaluate()\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/eval_results.json\", \"w\") as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3210e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"load_tests\": all_metrics_summary,\n",
    "    \"eval_results\": eval_results,\n",
    "    \"config\": {\n",
    "        \"model\": MODEL_NAME_OR_PATH,\n",
    "        \"device\": DEVICE,\n",
    "        \"num_requests\": NUM_REQUESTS,\n",
    "        \"concurrencies\": CONCURRENCIES\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "logger.info(\"Evaluation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcd84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
